The WebCrawler Pagerank project aims to investigate how web pages are connected on the internet in order to assess their importance or relevance, known as "PageRank." Using advanced web crawling algorithms, this project explores the vastness of the World Wide Web by following links and analyzing pages to measure their significance.

This Python-based web crawler is designed to retrieve and store web page data into an SQLite database. It allows users to execute queries on the collected data using Python's SQLite library, facilitating efficient data retrieval and manipulation.

